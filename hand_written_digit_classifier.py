# -*- coding: utf-8 -*-
"""Hand_written_digit_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/gist/fatemehes75/f1cb997d210a05c6815879b41cf002b6/hand_written_digit_classifier.ipynb

# Hand written digit classifier using numpy

Importing Library
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import time

"""Importing Dataset"""

from sklearn.datasets import fetch_openml
from keras.utils.np_utils import to_categorical
x, y = fetch_openml('mnist_784', version=1, return_X_y=True)
x = (x/255).astype('float32')#Normalization
y = to_categorical(y)#Converts a class vector (0 to 9) to binary class matrix.

print(y)

"""Spliting dataset"""

from sklearn.model_selection import train_test_split
x_train,x_val,y_train,y_val = train_test_split(x,y,test_size=0.2,random_state=1)

print(y_val)

"""Definning neural network"""

class Network():

    def __init__(self,sizes,epochs=10,learning_rate=0.3): #we can tune the learning rate. 
        self.sizes = sizes
        self.epochs = epochs
        self.learning_rate = learning_rate
        self.params = self.initialization()

    def sigmoid_func(self,x,derivative=False):
      g = 1/(1+np.exp(-x))
      if derivative:
            return (np.exp(-x))/((np.exp(-x)+1)**2)
      return g
    def softmax_func(self,x,derivative=False):
        exps = np.exp(x-x.max())
        s = exps/np.sum(exps,axis=0)
        if derivative:
            return exps/np.sum(exps,axis=0) * (1-exps/np.sum(exps, axis=0)) 
        return s

    def initialization(self):
        inputnodes=self.sizes[0]
        hiddennodes1=self.sizes[1]
        hiddennodes2=self.sizes[2]
        outputnodes=self.sizes[3]

        params = { 'theta1':np.random.randn(hiddennodes1,inputnodes)*np.sqrt(1./hiddennodes1), #random theta*(sqrt(1/n))
                   'theta2':np.random.randn(hiddennodes2,hiddennodes1)*np.sqrt(1./hiddennodes2),
                   'theta3':np.random.randn(outputnodes,hiddennodes2)*np.sqrt(1./outputnodes)}
        return params

    def forward_prop(self,x_train): 
        params = self.params
        params['a1'] = x_train
        params['z2'] = np.dot(params["theta1"], params['a1']) #np.dot => If both inputs are 2-D arrays, it is matrix multiplication
        params['a2'] = self.sigmoid_func(params['z2'])
        params['z3'] = np.dot(params["theta2"], params['a2'])
        params['a3'] = self.sigmoid_func(params['z3'])
        params['z4'] = np.dot(params["theta3"], params['a3'])
        params['a4'] = self.softmax_func(params['z4'])
        return params['a4']

    def backward_prop(self, y_train, output):
        params = self.params
        newtheta = {}
        delta = 2*(output-y_train)/output.shape[0] * self.softmax_func(params['z4'],derivative=True)
        newtheta['theta3'] = np.outer(delta,params['a3'])
        delta = np.dot(params['theta3'].T,delta) * self.sigmoid_func(params['z3'],derivative=True)
        newtheta['theta2'] = np.outer(delta,params['a2'])
        delta = np.dot(params['theta2'].T,delta) * self.sigmoid_func(params['z2'],derivative=True)
        newtheta['theta1'] = np.outer(delta,params['a1'])
        return newtheta

    def new_thetas(self,newtheta):
        for key, value in newtheta.items():
            self.params[key] = self.params[key]-self.learning_rate * value

    def Evaluation(self,x_val,y_val):
        predictions = []
        for x, y in zip(x_val,y_val):
            output = self.forward_prop(x) #doing a forward pass of x
            max_output = np.argmax(output) 
            predictions.append(max_output == np.argmax(y))  #checks if the indices of the maximum value in the output equals the indices in the label y
            # sum over prediction
        return np.mean(predictions) #return the average of the accuracy 

    def train(self,x_train,y_train,x_val,y_val):
      t_start = time.time()
      #train over all epochs
      for i in range(self.epochs):
            for x,y in zip(x_train,y_train):
                output = self.forward_prop(x)
                newtheta = self.backward_prop(y,output)
                self.new_thetas(newtheta)
            accuracy = self.Evaluation(x_val, y_val)
            print('epoch:{0},time:{1:.2f}s,accuracy: {2:.3f}%'.format(i+1,time.time() - t_start, accuracy * 100))
        
ANN = Network(sizes=[784, 128, 64, 10])
ANN.train(x_train,y_train,x_val,y_val)